{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\My Drive\\Data_Projects\\MDS\\master_thesis\\fiscal-balance-forecast\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 7 variables whereas the saved optimizer has 2 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REading File: ../data/data_cleaned_RFE.csv\n",
      "Outlier Threshold: nan\n",
      "Epoch 1/75\n",
      "5/5 - 1s - 180ms/step - loss: 5.3687 - val_loss: 4.5150\n",
      "Epoch 2/75\n",
      "5/5 - 0s - 11ms/step - loss: 4.1086 - val_loss: 3.8881\n",
      "Epoch 3/75\n",
      "5/5 - 0s - 10ms/step - loss: 3.6108 - val_loss: 3.5777\n",
      "Epoch 4/75\n",
      "5/5 - 0s - 15ms/step - loss: 3.4221 - val_loss: 3.3883\n",
      "Epoch 5/75\n",
      "5/5 - 0s - 11ms/step - loss: 3.2690 - val_loss: 3.2628\n",
      "Epoch 6/75\n",
      "5/5 - 0s - 12ms/step - loss: 3.1687 - val_loss: 3.1611\n",
      "Epoch 7/75\n",
      "5/5 - 0s - 11ms/step - loss: 3.0895 - val_loss: 3.0553\n",
      "Epoch 8/75\n",
      "5/5 - 0s - 13ms/step - loss: 2.9938 - val_loss: 2.9580\n",
      "Epoch 9/75\n",
      "5/5 - 0s - 10ms/step - loss: 2.8982 - val_loss: 2.8658\n",
      "Epoch 10/75\n",
      "5/5 - 0s - 11ms/step - loss: 2.8089 - val_loss: 2.7513\n",
      "Epoch 11/75\n",
      "5/5 - 0s - 11ms/step - loss: 2.7255 - val_loss: 2.6673\n",
      "Epoch 12/75\n",
      "5/5 - 0s - 11ms/step - loss: 2.6048 - val_loss: 2.5644\n",
      "Epoch 13/75\n",
      "5/5 - 0s - 12ms/step - loss: 2.5193 - val_loss: 2.4847\n",
      "Epoch 14/75\n",
      "5/5 - 0s - 13ms/step - loss: 2.4198 - val_loss: 2.3815\n",
      "Epoch 15/75\n",
      "5/5 - 0s - 10ms/step - loss: 2.3342 - val_loss: 2.3073\n",
      "Epoch 16/75\n",
      "5/5 - 0s - 12ms/step - loss: 2.2442 - val_loss: 2.2011\n",
      "Epoch 17/75\n",
      "5/5 - 0s - 12ms/step - loss: 2.1608 - val_loss: 2.1141\n",
      "Epoch 18/75\n",
      "5/5 - 0s - 11ms/step - loss: 2.0755 - val_loss: 2.0165\n",
      "Epoch 19/75\n",
      "5/5 - 0s - 10ms/step - loss: 1.9861 - val_loss: 1.9467\n",
      "Epoch 20/75\n",
      "5/5 - 0s - 11ms/step - loss: 1.9085 - val_loss: 1.8699\n",
      "Epoch 21/75\n",
      "5/5 - 0s - 14ms/step - loss: 1.8361 - val_loss: 1.7947\n",
      "Epoch 22/75\n",
      "5/5 - 0s - 15ms/step - loss: 1.7586 - val_loss: 1.7106\n",
      "Epoch 23/75\n",
      "5/5 - 0s - 10ms/step - loss: 1.6772 - val_loss: 1.6311\n",
      "Epoch 24/75\n",
      "5/5 - 0s - 13ms/step - loss: 1.6086 - val_loss: 1.5708\n",
      "Epoch 25/75\n",
      "5/5 - 0s - 10ms/step - loss: 1.5346 - val_loss: 1.4951\n",
      "Epoch 26/75\n",
      "5/5 - 0s - 10ms/step - loss: 1.4694 - val_loss: 1.4247\n",
      "Epoch 27/75\n",
      "5/5 - 0s - 10ms/step - loss: 1.3976 - val_loss: 1.3623\n",
      "Epoch 28/75\n",
      "5/5 - 0s - 13ms/step - loss: 1.3311 - val_loss: 1.3014\n",
      "Epoch 29/75\n",
      "5/5 - 0s - 13ms/step - loss: 1.2746 - val_loss: 1.2477\n",
      "Epoch 30/75\n",
      "5/5 - 0s - 13ms/step - loss: 1.2175 - val_loss: 1.1824\n",
      "Epoch 31/75\n",
      "5/5 - 0s - 11ms/step - loss: 1.1487 - val_loss: 1.1317\n",
      "Epoch 32/75\n",
      "5/5 - 0s - 12ms/step - loss: 1.0994 - val_loss: 1.0697\n",
      "Epoch 33/75\n",
      "5/5 - 0s - 11ms/step - loss: 1.0455 - val_loss: 1.0271\n",
      "Epoch 34/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.9971 - val_loss: 0.9754\n",
      "Epoch 35/75\n",
      "5/5 - 0s - 9ms/step - loss: 0.9364 - val_loss: 0.9210\n",
      "Epoch 36/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.8906 - val_loss: 0.8774\n",
      "Epoch 37/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.8517 - val_loss: 0.8258\n",
      "Epoch 38/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.7998 - val_loss: 0.7847\n",
      "Epoch 39/75\n",
      "5/5 - 0s - 18ms/step - loss: 0.7627 - val_loss: 0.7481\n",
      "Epoch 40/75\n",
      "5/5 - 0s - 29ms/step - loss: 0.7192 - val_loss: 0.7156\n",
      "Epoch 41/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.6751 - val_loss: 0.6857\n",
      "Epoch 42/75\n",
      "5/5 - 0s - 14ms/step - loss: 0.6453 - val_loss: 0.6345\n",
      "Epoch 43/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.6086 - val_loss: 0.6059\n",
      "Epoch 44/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.5735 - val_loss: 0.5677\n",
      "Epoch 45/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.5468 - val_loss: 0.5382\n",
      "Epoch 46/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.5136 - val_loss: 0.5185\n",
      "Epoch 47/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.4880 - val_loss: 0.4803\n",
      "Epoch 48/75\n",
      "5/5 - 0s - 14ms/step - loss: 0.4602 - val_loss: 0.4565\n",
      "Epoch 49/75\n",
      "5/5 - 0s - 14ms/step - loss: 0.4362 - val_loss: 0.4317\n",
      "Epoch 50/75\n",
      "5/5 - 0s - 8ms/step - loss: 0.4147 - val_loss: 0.4081\n",
      "Epoch 51/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.3885 - val_loss: 0.3879\n",
      "Epoch 52/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.3748 - val_loss: 0.3775\n",
      "Epoch 53/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.3548 - val_loss: 0.3602\n",
      "Epoch 54/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.3364 - val_loss: 0.3351\n",
      "Epoch 55/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.3189 - val_loss: 0.3227\n",
      "Epoch 56/75\n",
      "5/5 - 0s - 14ms/step - loss: 0.3101 - val_loss: 0.3121\n",
      "Epoch 57/75\n",
      "5/5 - 0s - 15ms/step - loss: 0.2962 - val_loss: 0.2984\n",
      "Epoch 58/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.2826 - val_loss: 0.2890\n",
      "Epoch 59/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.2765 - val_loss: 0.2851\n",
      "Epoch 60/75\n",
      "5/5 - 0s - 16ms/step - loss: 0.2641 - val_loss: 0.2734\n",
      "Epoch 61/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.2553 - val_loss: 0.2630\n",
      "Epoch 62/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.2438 - val_loss: 0.2577\n",
      "Epoch 63/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.2440 - val_loss: 0.2467\n",
      "Epoch 64/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.2308 - val_loss: 0.2419\n",
      "Epoch 65/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.2297 - val_loss: 0.2353\n",
      "Epoch 66/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.2216 - val_loss: 0.2340\n",
      "Epoch 67/75\n",
      "5/5 - 0s - 15ms/step - loss: 0.2192 - val_loss: 0.2237\n",
      "Epoch 68/75\n",
      "5/5 - 0s - 14ms/step - loss: 0.2064 - val_loss: 0.2192\n",
      "Epoch 69/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.2053 - val_loss: 0.2140\n",
      "Epoch 70/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.1979 - val_loss: 0.2093\n",
      "Epoch 71/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.1921 - val_loss: 0.2041\n",
      "Epoch 72/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.1886 - val_loss: 0.2008\n",
      "Epoch 73/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.1844 - val_loss: 0.1951\n",
      "Epoch 74/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.1824 - val_loss: 0.1942\n",
      "Epoch 75/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.1784 - val_loss: 0.1875\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "Outlier Threshold: 0.05\n",
      "Epoch 1/75\n",
      "5/5 - 0s - 19ms/step - loss: 0.1717 - val_loss: 0.1839\n",
      "Epoch 2/75\n",
      "5/5 - 0s - 24ms/step - loss: 0.1696 - val_loss: 0.1843\n",
      "Epoch 3/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.1672 - val_loss: 0.1787\n",
      "Epoch 4/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.1614 - val_loss: 0.1771\n",
      "Epoch 5/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.1604 - val_loss: 0.1744\n",
      "Epoch 6/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.1585 - val_loss: 0.1720\n",
      "Epoch 7/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.1575 - val_loss: 0.1710\n",
      "Epoch 8/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.1559 - val_loss: 0.1683\n",
      "Epoch 9/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.1510 - val_loss: 0.1664\n",
      "Epoch 10/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.1553 - val_loss: 0.1648\n",
      "Epoch 11/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.1523 - val_loss: 0.1647\n",
      "Epoch 12/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.1443 - val_loss: 0.1648\n",
      "Epoch 13/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.1424 - val_loss: 0.1629\n",
      "Epoch 14/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.1408 - val_loss: 0.1617\n",
      "Epoch 15/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.1410 - val_loss: 0.1566\n",
      "Epoch 16/75\n",
      "5/5 - 0s - 15ms/step - loss: 0.1396 - val_loss: 0.1550\n",
      "Epoch 17/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.1376 - val_loss: 0.1586\n",
      "Epoch 18/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.1313 - val_loss: 0.1513\n",
      "Epoch 19/75\n",
      "5/5 - 0s - 14ms/step - loss: 0.1324 - val_loss: 0.1504\n",
      "Epoch 20/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.1316 - val_loss: 0.1540\n",
      "Epoch 21/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.1321 - val_loss: 0.1578\n",
      "Epoch 22/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.1266 - val_loss: 0.1459\n",
      "Epoch 23/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.1252 - val_loss: 0.1442\n",
      "Epoch 24/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.1254 - val_loss: 0.1430\n",
      "Epoch 25/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.1253 - val_loss: 0.1422\n",
      "Epoch 26/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.1210 - val_loss: 0.1421\n",
      "Epoch 27/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.1202 - val_loss: 0.1399\n",
      "Epoch 28/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.1170 - val_loss: 0.1385\n",
      "Epoch 29/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.1197 - val_loss: 0.1375\n",
      "Epoch 30/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.1142 - val_loss: 0.1355\n",
      "Epoch 31/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.1140 - val_loss: 0.1342\n",
      "Epoch 32/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.1159 - val_loss: 0.1336\n",
      "Epoch 33/75\n",
      "5/5 - 0s - 15ms/step - loss: 0.1146 - val_loss: 0.1322\n",
      "Epoch 34/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.1080 - val_loss: 0.1305\n",
      "Epoch 35/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.1101 - val_loss: 0.1333\n",
      "Epoch 36/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.1104 - val_loss: 0.1280\n",
      "Epoch 37/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.1069 - val_loss: 0.1331\n",
      "Epoch 38/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.1068 - val_loss: 0.1281\n",
      "Epoch 39/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.1053 - val_loss: 0.1265\n",
      "Epoch 40/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.1017 - val_loss: 0.1229\n",
      "Epoch 41/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.1030 - val_loss: 0.1230\n",
      "Epoch 42/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.1008 - val_loss: 0.1210\n",
      "Epoch 43/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.0976 - val_loss: 0.1228\n",
      "Epoch 44/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.1004 - val_loss: 0.1191\n",
      "Epoch 45/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0973 - val_loss: 0.1193\n",
      "Epoch 46/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0977 - val_loss: 0.1181\n",
      "Epoch 47/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0942 - val_loss: 0.1160\n",
      "Epoch 48/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.0918 - val_loss: 0.1149\n",
      "Epoch 49/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.0913 - val_loss: 0.1136\n",
      "Epoch 50/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.0922 - val_loss: 0.1144\n",
      "Epoch 51/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.0906 - val_loss: 0.1112\n",
      "Epoch 52/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0887 - val_loss: 0.1114\n",
      "Epoch 53/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0880 - val_loss: 0.1092\n",
      "Epoch 54/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0853 - val_loss: 0.1109\n",
      "Epoch 55/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0888 - val_loss: 0.1076\n",
      "Epoch 56/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0838 - val_loss: 0.1084\n",
      "Epoch 57/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0875 - val_loss: 0.1094\n",
      "Epoch 58/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0864 - val_loss: 0.1038\n",
      "Epoch 59/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0809 - val_loss: 0.1045\n",
      "Epoch 60/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0811 - val_loss: 0.1015\n",
      "Epoch 61/75\n",
      "5/5 - 0s - 9ms/step - loss: 0.0791 - val_loss: 0.1018\n",
      "Epoch 62/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0799 - val_loss: 0.1002\n",
      "Epoch 63/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0787 - val_loss: 0.1032\n",
      "Epoch 64/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0769 - val_loss: 0.0995\n",
      "Epoch 65/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0759 - val_loss: 0.1001\n",
      "Epoch 66/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0747 - val_loss: 0.0967\n",
      "Epoch 67/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0717 - val_loss: 0.0996\n",
      "Epoch 68/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.0719 - val_loss: 0.0948\n",
      "Epoch 69/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0717 - val_loss: 0.0952\n",
      "Epoch 70/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0692 - val_loss: 0.0947\n",
      "Epoch 71/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0727 - val_loss: 0.0972\n",
      "Epoch 72/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0687 - val_loss: 0.0907\n",
      "Epoch 73/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0674 - val_loss: 0.0907\n",
      "Epoch 74/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0663 - val_loss: 0.0916\n",
      "Epoch 75/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0660 - val_loss: 0.0889\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Outlier Threshold: 0.1\n",
      "Epoch 1/75\n",
      "5/5 - 0s - 18ms/step - loss: 0.0647 - val_loss: 0.0902\n",
      "Epoch 2/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0656 - val_loss: 0.0951\n",
      "Epoch 3/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.0643 - val_loss: 0.0890\n",
      "Epoch 4/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.0640 - val_loss: 0.0855\n",
      "Epoch 5/75\n",
      "5/5 - 0s - 14ms/step - loss: 0.0637 - val_loss: 0.0883\n",
      "Epoch 6/75\n",
      "5/5 - 0s - 9ms/step - loss: 0.0614 - val_loss: 0.0907\n",
      "Epoch 7/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.0600 - val_loss: 0.0883\n",
      "Epoch 8/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.0599 - val_loss: 0.0830\n",
      "Epoch 9/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.0589 - val_loss: 0.0834\n",
      "Epoch 10/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.0574 - val_loss: 0.0807\n",
      "Epoch 11/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0573 - val_loss: 0.0846\n",
      "Epoch 12/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0557 - val_loss: 0.0792\n",
      "Epoch 13/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.0560 - val_loss: 0.0828\n",
      "Epoch 14/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.0521 - val_loss: 0.0783\n",
      "Epoch 15/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.0536 - val_loss: 0.0769\n",
      "Epoch 16/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0534 - val_loss: 0.0964\n",
      "Epoch 17/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0551 - val_loss: 0.0761\n",
      "Epoch 18/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0497 - val_loss: 0.0771\n",
      "Epoch 19/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.0496 - val_loss: 0.0732\n",
      "Epoch 20/75\n",
      "5/5 - 0s - 16ms/step - loss: 0.0500 - val_loss: 0.0731\n",
      "Epoch 21/75\n",
      "5/5 - 0s - 14ms/step - loss: 0.0482 - val_loss: 0.0801\n",
      "Epoch 22/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.0470 - val_loss: 0.0713\n",
      "Epoch 23/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0464 - val_loss: 0.0714\n",
      "Epoch 24/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0480 - val_loss: 0.0727\n",
      "Epoch 25/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0454 - val_loss: 0.0707\n",
      "Epoch 26/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0431 - val_loss: 0.0740\n",
      "Epoch 27/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.0426 - val_loss: 0.0681\n",
      "Epoch 28/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.0437 - val_loss: 0.0707\n",
      "Epoch 29/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.0413 - val_loss: 0.0782\n",
      "Epoch 30/75\n",
      "5/5 - 0s - 9ms/step - loss: 0.0413 - val_loss: 0.0663\n",
      "Epoch 31/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0409 - val_loss: 0.0703\n",
      "Epoch 32/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.0420 - val_loss: 0.0650\n",
      "Epoch 33/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.0390 - val_loss: 0.0683\n",
      "Epoch 34/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.0393 - val_loss: 0.0752\n",
      "Epoch 35/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.0389 - val_loss: 0.0726\n",
      "Epoch 36/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.0365 - val_loss: 0.0744\n",
      "Epoch 37/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.0381 - val_loss: 0.0649\n",
      "Epoch 38/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.0355 - val_loss: 0.0662\n",
      "Epoch 39/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0353 - val_loss: 0.0670\n",
      "Epoch 40/75\n",
      "5/5 - 0s - 14ms/step - loss: 0.0365 - val_loss: 0.0617\n",
      "Epoch 41/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0336 - val_loss: 0.0619\n",
      "Epoch 42/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.0331 - val_loss: 0.0618\n",
      "Epoch 43/75\n",
      "5/5 - 0s - 17ms/step - loss: 0.0337 - val_loss: 0.0694\n",
      "Epoch 44/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.0332 - val_loss: 0.0609\n",
      "Epoch 45/75\n",
      "5/5 - 0s - 15ms/step - loss: 0.0325 - val_loss: 0.0562\n",
      "Epoch 46/75\n",
      "5/5 - 0s - 22ms/step - loss: 0.0323 - val_loss: 0.0694\n",
      "Epoch 47/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.0301 - val_loss: 0.0578\n",
      "Epoch 48/75\n",
      "5/5 - 0s - 14ms/step - loss: 0.0293 - val_loss: 0.0564\n",
      "Epoch 49/75\n",
      "5/5 - 0s - 10ms/step - loss: 0.0278 - val_loss: 0.0560\n",
      "Epoch 50/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.0292 - val_loss: 0.0578\n",
      "Epoch 51/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0277 - val_loss: 0.0605\n",
      "Epoch 52/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0262 - val_loss: 0.0672\n",
      "Epoch 53/75\n",
      "5/5 - 0s - 14ms/step - loss: 0.0271 - val_loss: 0.0616\n",
      "Epoch 54/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.0260 - val_loss: 0.0633\n",
      "Epoch 55/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0255 - val_loss: 0.0587\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Outlier Threshold: 0.15\n",
      "Epoch 1/75\n",
      "5/5 - 0s - 15ms/step - loss: 0.0297 - val_loss: 0.0689\n",
      "Epoch 2/75\n",
      "5/5 - 0s - 14ms/step - loss: 0.0279 - val_loss: 0.0530\n",
      "Epoch 3/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.0269 - val_loss: 0.0667\n",
      "Epoch 4/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0267 - val_loss: 0.0566\n",
      "Epoch 5/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0266 - val_loss: 0.0711\n",
      "Epoch 6/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0253 - val_loss: 0.0705\n",
      "Epoch 7/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0261 - val_loss: 0.0642\n",
      "Epoch 8/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0249 - val_loss: 0.0533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Outlier Threshold: 0.2\n",
      "Epoch 1/75\n",
      "5/5 - 0s - 19ms/step - loss: 0.0501 - val_loss: 0.1992\n",
      "Epoch 2/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0447 - val_loss: 0.1894\n",
      "Epoch 3/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0428 - val_loss: 0.2129\n",
      "Epoch 4/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0430 - val_loss: 0.1823\n",
      "Epoch 5/75\n",
      "5/5 - 0s - 12ms/step - loss: 0.0419 - val_loss: 0.1877\n",
      "Epoch 6/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0409 - val_loss: 0.1824\n",
      "Epoch 7/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0425 - val_loss: 0.1988\n",
      "Epoch 8/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0434 - val_loss: 0.1886\n",
      "Epoch 9/75\n",
      "5/5 - 0s - 13ms/step - loss: 0.0392 - val_loss: 0.1842\n",
      "Epoch 10/75\n",
      "5/5 - 0s - 11ms/step - loss: 0.0398 - val_loss: 0.2021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "File: ../data/data_cleaned_RFE.csv, Outlier Threshold: nan -> Errors: {'MAPE': 1.0353479, 'RMSE': 43451.895, 'MAE': 33882.984}\n",
      "File: ../data/data_cleaned_RFE.csv, Outlier Threshold: 0.05 -> Errors: {'MAPE': 1.0472882, 'RMSE': 42390.434, 'MAE': 32537.738}\n",
      "File: ../data/data_cleaned_RFE.csv, Outlier Threshold: 0.1 -> Errors: {'MAPE': 2.0150528, 'RMSE': 25497.973, 'MAE': 22461.87}\n",
      "File: ../data/data_cleaned_RFE.csv, Outlier Threshold: 0.15 -> Errors: {'MAPE': 2.647292, 'RMSE': 25021.037, 'MAE': 22052.945}\n",
      "File: ../data/data_cleaned_RFE.csv, Outlier Threshold: 0.2 -> Errors: {'MAPE': 0.99935865, 'RMSE': 22848.58, 'MAE': 19477.549}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import useful_functions as uf\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "# Possible datasets to test\n",
    "file_paths = [\n",
    "    #'../data/data_orig_parameters.csv'\n",
    "    # '../data/BR_param_EDA.csv',\n",
    "    #'../data/data_cleaned_RF.csv',\n",
    "    #'../data/data_cleaned_LASSO.csv',\n",
    "    '../data/data_cleaned_RFE.csv'\n",
    "]\n",
    "\n",
    "# List of outlier thresholds to test\n",
    "outlier_thresholds = [np.nan, 0.05, 0.10, 0.15, 0.20]\n",
    "\n",
    "# Dictionary to store the errors\n",
    "errors_dict = {}\n",
    "\n",
    "# Load the model from the file\n",
    "best_model = load_model('best_lstm_model_grid_rfe_6.keras')\n",
    "# from manual hyperparameter tuning\n",
    "epochs = 75\n",
    "batch_size = 32\n",
    "patience = 6\n",
    "\n",
    "# Loop through the files and outlier thresholds\n",
    "for file_path in file_paths:\n",
    "    print(f\"REading File: {file_path}\")\n",
    "    for remove_outliers_threshold in outlier_thresholds:\n",
    "        print(f\"Outlier Threshold: {remove_outliers_threshold}\")\n",
    "        # Load  data\n",
    "        df_raw = pd.read_csv(file_path, parse_dates=['Date'], index_col='Date')\n",
    "        target_variable = df_raw.columns[0]\n",
    "        # Convert all columns to float\n",
    "        df_raw = df_raw.astype('float64')   \n",
    "        df = df_raw.copy()\n",
    "\n",
    "        # Remove outliers using the threshold\n",
    "        if not pd.isna(remove_outliers_threshold):\n",
    "            df_cleaned = uf.remove_outliers(df.copy(), threshold=remove_outliers_threshold)\n",
    "        else:\n",
    "            df_cleaned = df.copy()\n",
    "\n",
    "        # Fill missing values\n",
    "        df_adjusted = uf.fill_missing_values(df_cleaned)\n",
    "\n",
    "        # Define test, train and validation set sizes\n",
    "        val_size = 48 # 48 months or 4 years\n",
    "        test_size = 48 # 48 months or 4 years\n",
    "\n",
    "        # Split the data into train and test sets\n",
    "        train_raw_total = df_adjusted[:-test_size] # This total trainning set will be used to train the final model\n",
    "        df_train = train_raw_total[:-val_size]\n",
    "        df_val = train_raw_total[-val_size:]\n",
    "        df_test = df_adjusted[-test_size:]\n",
    "\n",
    "        # Let´s scale the dfs\n",
    "\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        scaled_train = scaler.fit_transform(df_train)\n",
    "        scaled_val = scaler.transform(df_val)\n",
    "        scaled_test = scaler.transform(df_test)\n",
    "        # include df columns names in the train and test sets\n",
    "        train = pd.DataFrame(scaled_train, columns=df_train.columns)\n",
    "        val = pd.DataFrame(scaled_val, columns=df_val.columns)\n",
    "        test = pd.DataFrame(scaled_test, columns=df_test.columns)\n",
    "        # Include the index in the train and test sets\n",
    "        train.index = df_train.index\n",
    "        val.index = df_val.index\n",
    "        test.index = df_test.index\n",
    "\n",
    "        # Converting the series to samples\n",
    "        # We will use the past 12 months to predict the next 12 months\n",
    "        def createXY(dataset, n_past, n_future):\n",
    "            dataX, dataY = [], []\n",
    "            # Loop for the entire dataset\n",
    "            for i in range(n_past, len(dataset) - n_future + 1):\n",
    "                dataX.append(dataset.iloc[i - n_past:i].values)  # Past n months\n",
    "                dataY.append(dataset.iloc[i + n_future - 1, 0])  #\n",
    "            return np.array(dataX), np.array(dataY)\n",
    "\n",
    "        n_past = 12  # Number of past months to use\n",
    "        n_future = 12  # Number of future months to predict\n",
    "\n",
    "        # Create the samples\n",
    "        X_train, Y_train = createXY(train, n_past, n_future)\n",
    "        X_val, Y_val = createXY(val, n_past, n_future)\n",
    "        X_test, Y_test = createXY(test, n_past, n_future)\n",
    "\n",
    "        # Define EarlyStopping callback\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True) # Stop training when the validation loss is no longer decreasing after X epochs\n",
    "\n",
    "\n",
    "        # train the model\n",
    "        history = best_model.fit(X_train, Y_train, \n",
    "                                 validation_data=(X_val, Y_val), \n",
    "                                 epochs=epochs, batch_size=batch_size, \n",
    "                                 verbose=2,callbacks=[early_stopping]) \n",
    "                                 #callbacks=[early_stopping])\n",
    "        # Let's predict the test set using the best model\n",
    "        predictions_test_scaled = best_model.predict(X_test)\n",
    "\n",
    "        # Let's reshape the predictions and Y_val to revert the scaling\n",
    "        # Reshape predictions to 2D\n",
    "        predictions_test_scaled_2d = predictions_test_scaled.reshape(-1, 1)\n",
    "        # Get the last timestep of X_test\n",
    "        X_test_last_timestep = X_test[:, -1, :]\n",
    "        # Replace the first column of X_test_last_timestep with the scaled predictions.\n",
    "        X_test_last_timestep[:, 0] = predictions_test_scaled_2d[:, 0]\n",
    "        # unscale the predictions\n",
    "        predictions_test_rescaled = scaler.inverse_transform(X_test_last_timestep)[:, 0]\n",
    "\n",
    "        # Let's convert the predictions and Y_test to a dataframe usind the index from test\n",
    "        predictions_test_df = pd.DataFrame(predictions_test_rescaled, index=test.index[-len(predictions_test_rescaled):], columns=[target_variable])\n",
    "\n",
    "        # Reverse the decomposition of the time series\n",
    "        #predictions = recompose_time_series(predictions_test_df, decomp_dict)\n",
    "        predictions = predictions_test_df.copy()\n",
    "        Y_test = df_adjusted[-len(predictions):][target_variable]\n",
    "\n",
    "        # Calculate the error\n",
    "        mape_best_LSTM = mean_absolute_percentage_error(Y_test, predictions)\n",
    "        rmse_best_LSTM = np.sqrt(mean_squared_error(Y_test, predictions))\n",
    "        mae_best_LSTM = mean_absolute_error(Y_test, predictions)\n",
    "\n",
    "        #print(f'MAPE best LSTM: {mape_best_LSTM}')\n",
    "        #print(f'RMSE best LSTM: {rmse_best_LSTM}')\n",
    "        #print(f'MAE best LSTM: {mae_best_LSTM}')\n",
    "\n",
    "        # Armazenamento dos erros no dicionário\n",
    "        errors_dict[(file_path, remove_outliers_threshold)] = {'MAPE': mape_best_LSTM, 'RMSE': rmse_best_LSTM, 'MAE': mae_best_LSTM}\n",
    "\n",
    "# Exibição dos resultados\n",
    "for key, value in errors_dict.items():\n",
    "    print(f\"File: {key[0]}, Outlier Threshold: {key[1]} -> Errors: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('../data/data_cleaned_RFE.csv', nan): {'MAPE': 1.0353479, 'RMSE': 43451.895, 'MAE': 33882.984}, ('../data/data_cleaned_RFE.csv', 0.05): {'MAPE': 1.0472882, 'RMSE': 42390.434, 'MAE': 32537.738}, ('../data/data_cleaned_RFE.csv', 0.1): {'MAPE': 2.0150528, 'RMSE': 25497.973, 'MAE': 22461.87}, ('../data/data_cleaned_RFE.csv', 0.15): {'MAPE': 2.647292, 'RMSE': 25021.037, 'MAE': 22052.945}, ('../data/data_cleaned_RFE.csv', 0.2): {'MAPE': 0.99935865, 'RMSE': 22848.58, 'MAE': 19477.549}}\n"
     ]
    }
   ],
   "source": [
    "print(errors_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
