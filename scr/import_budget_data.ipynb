{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script imports brazilian budget execution data\n",
    "Source of data: https://www.siop.planejamento.gov.br/modulo/login/index.html#/\n",
    "Data collected in Jan, 25th, 2024.\n",
    "\n",
    "Função 9 - Previdência, Função 10 - Saúde, Função 12 - Educação\n",
    "\n",
    "GND 4 e 5 - Investimentos e inversões financeiras\n",
    "GND 1 - Pessoal\n",
    "\n",
    "Rp 1 - Obrigatórias\n",
    "RP 2+ 3 - Discricionárias\n",
    "Rp 6+7+8+9 - Emendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\augus\\AppData\\Local\\Temp\\ipykernel_27972\\688652929.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import useful_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "df_budget_raw = pd.read_excel('../data/dF_budget_raw_2001-2023_25.01.2024.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df_budget_raw.rename(columns={'Ano': 'year','Função': 'function', 'Grupo de Despesa': 'group', 'Resultado Primário': 'type', 'Empenhado': 'spent_value','Dotação Inicial': 'initial_value' }, inplace=True)\n",
    "\n",
    "# Extract codes for each column\n",
    "df_budget_raw['function_code'] = df_budget_raw['function'].str.split(' ', n = 1).str[0]\n",
    "df_budget_raw['group_code'] = df_budget_raw['group'].str.split(' ', n = 1).str[0]\n",
    "df_budget_raw['type_code'] = df_budget_raw['type'].str.split(' ', n = 1).str[0]\n",
    "\n",
    "# Reorder columns\n",
    "df_budget_raw = df_budget_raw.reindex(columns=['year', 'function', 'function_code', 'group', 'group_code', 'type', 'type_code', 'initial_value', 'spent_value'])\n",
    "\n",
    "# Adjust the values format\n",
    "for value in ['initial_value', 'spent_value']:\n",
    "    df_budget_raw[value] = df_budget_raw[value].str.replace('.', '').str.replace(',', '.').astype(float)\n",
    "\n",
    "\n",
    "# Filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_functions = ['09', '10', '12'] #Function 9 - Pension, Function 10 - Health, Function 12 - Education\n",
    "\n",
    "desired_groups = ['1', '4', '5'] # Group 1 - Personal, Group 4 - Investiments and group 5 - Financial changes\n",
    "\n",
    "desired_types = ['1', '2', '3', '6', '7', '8', '9'] # Group 1 - Personal, Group 4 - Investiments and group 5 - Financial changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create some copies of the original dataframe\n",
    "\n",
    "# Filter by function\n",
    "df_function = df_budget_raw[df_budget_raw['function_code'].isin(desired_functions)].copy()[['year', 'function', 'function_code', 'initial_value', 'spent_value']]\n",
    "df_function.rename(columns={'function_code': 'code'}, inplace=True)\n",
    "\n",
    "# Filter by group\n",
    "df_group = df_budget_raw[df_budget_raw['group_code'].isin(desired_groups)].copy()[['year', 'group', 'group_code', 'initial_value', 'spent_value']]\n",
    "df_group.rename(columns={'group_code': 'code'}, inplace=True)\n",
    "\n",
    "# Filter by type\n",
    "df_type = df_budget_raw[df_budget_raw['type_code'].isin(desired_types)].copy()[['year', 'type', 'type_code', 'initial_value', 'spent_value']]\n",
    "df_type.rename(columns={'type_code': 'code'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some adjustments for function df\n",
    "\n",
    "# Group df_function by year and sum the values\n",
    "df_step= df_function.groupby(['year', 'code']).sum().reset_index()\n",
    "\n",
    "# Create a new dictionary to store the filtered dataframes\n",
    "filtered_dfs = {}\n",
    "\n",
    "# Loop through the types of values to create the filtered dataframes\n",
    "for i, value in enumerate(['initial_value', 'spent_value']):\n",
    "    \n",
    "    filtered_dfs[i]  = df_step[['year', 'code', value]].copy().pivot(index='year', columns='code', values=value) # filter and pivot the dataframe and them store it in the dictionary\n",
    "    \n",
    "    for column in filtered_dfs[i].columns:\n",
    "        filtered_dfs[i].rename(columns={column: f\"bud_fun_{column}_{value}\"}, inplace=True) # rename the columns to avoid confusion\n",
    "\n",
    "df_function = pd.concat(filtered_dfs.values(), axis=1) # concatenate the dataframes from the dictionary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some adjustments for group df\n",
    "\n",
    "# Group df_group by year and sum the values\n",
    "df_step= df_group.groupby(['year', 'code']).sum().reset_index()\n",
    "\n",
    "# Create a new dictionary to store the filtered dataframes\n",
    "filtered_dfs = {}\n",
    "\n",
    "# Loop through the types of values to create the filtered dataframes\n",
    "for i, value in enumerate(['initial_value', 'spent_value']):\n",
    "    \n",
    "    filtered_dfs[i]  = df_step[['year', 'code', value]].copy().pivot(index='year', columns='code', values=value) # filter and pivot the dataframe and them store it in the dictionary\n",
    "    \n",
    "    for column in filtered_dfs[i].columns:\n",
    "        filtered_dfs[i].rename(columns={column: f\"bud_group_{column}_{value}\"}, inplace=True) # rename the columns to avoid confusion\n",
    "\n",
    "# Concatenate the dataframes from the dictionary\n",
    "df_group = pd.concat(filtered_dfs.values(), axis=1)\n",
    "\n",
    "# Create new columns to store the sum of the initial values from the groups 4 and 5\n",
    "df_group['bud_group_invest_initial_value'] = df_group[['bud_group_4_initial_value', 'bud_group_5_initial_value']].sum(axis=1)\n",
    "df_group.drop(['bud_group_4_initial_value', 'bud_group_5_initial_value'], axis=1, inplace=True)\n",
    "\n",
    "# Create new columns to store the sum of the spent values from the groups 4 and 5\n",
    "df_group['bud_group_invest_spent_value'] = df_group[['bud_group_4_spent_value', 'bud_group_5_spent_value']].sum(axis=1)\n",
    "df_group.drop(['bud_group_4_spent_value', 'bud_group_5_spent_value'], axis=1, inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "df_group.rename(columns={'bud_group_1_initial_value': 'bud_group_personal_initial_value',\n",
    "                        'bud_group_1_spent_value': 'bud_group_personal_spent_value'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some adjustments for type df\n",
    "\n",
    "# Group df_type by year and sum the values\n",
    "df_step= df_type.groupby(['year', 'code']).sum().reset_index()\n",
    "\n",
    "# Create a new dictionary to store the filtered dataframes\n",
    "filtered_dfs = {}\n",
    "\n",
    "#   Loop through the types of values to create the filtered dataframes\n",
    "for i, value in enumerate(['initial_value', 'spent_value']):\n",
    "    \n",
    "    filtered_dfs[i]  = df_step[['year', 'code', value]].copy().pivot(index='year', columns='code', values=value) # filter and pivot the dataframe and them store it in the dictionary\n",
    "    \n",
    "    for column in filtered_dfs[i].columns:\n",
    "        filtered_dfs[i].rename(columns={column: f\"bud_type_{column}_{value}\"}, inplace=True) # rename the columns to avoid confusion\n",
    "\n",
    "# Concatenate the dataframes from the dictionary\n",
    "df_type = pd.concat(filtered_dfs.values(), axis=1)\n",
    "\n",
    "# Create new columns to store the sum of the initial values from the types 6, 7, 8 and 9\n",
    "df_type['bud_type_amendments_initial_value'] = df_type[['bud_type_6_initial_value', 'bud_type_7_initial_value', 'bud_type_8_initial_value', 'bud_type_9_initial_value']].sum(axis=1)\n",
    "df_type['bud_type_disc_initial_value'] = df_type[['bud_type_2_initial_value', 'bud_type_3_initial_value']].sum(axis=1)\n",
    "df_type.drop(['bud_type_6_initial_value', 'bud_type_7_initial_value', 'bud_type_8_initial_value', 'bud_type_9_initial_value', 'bud_type_2_initial_value', 'bud_type_3_initial_value'], axis=1, inplace=True)\n",
    "\n",
    "# Create new columns to store the sum of the spent values from the types 6, 7, 8 and 9\n",
    "df_type['bud_type_amendments_spent_value'] = df_type[['bud_type_6_spent_value', 'bud_type_7_spent_value', 'bud_type_8_spent_value', 'bud_type_9_spent_value']].sum(axis=1)\n",
    "df_type['bud_type_disc_spent_value'] = df_type[['bud_type_2_spent_value', 'bud_type_3_spent_value']].sum(axis=1)\n",
    "df_type.drop(['bud_type_6_spent_value', 'bud_type_7_spent_value', 'bud_type_8_spent_value', 'bud_type_9_spent_value', 'bud_type_2_spent_value', 'bud_type_3_spent_value'], axis=1, inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "df_type.rename(columns={'bud_type_1_initial_value': 'bud_type_mandatory_initial_value',\n",
    "                        'bud_type_1_spent_value': 'bud_type_mandatory_spent_value'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\augus\\AppData\\Local\\Temp\\ipykernel_27972\\1656709353.py:10: PerformanceWarning: Non-vectorized DateOffset being applied to Series or DatetimeIndex.\n",
      "  df_budget.index = pd.to_datetime(df_budget.index) + pd.DateOffset(month=12)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the dataframes\n",
    "df_budget = pd.concat([df_function, df_group, df_type], axis=1)\n",
    "\n",
    "# Convert time index to datetime and adjust its format.\n",
    "df_budget.index = pd.to_datetime(df_budget.index, format='%Y')\n",
    "\n",
    "\n",
    "# Change the day of the index to the last day of each year, since the data corresponds to the end of each year\n",
    "#df_budget.index = pd.to_datetime(df_budget.index) + pd.DateOffset(years=1) - pd.DateOffset(days=1)\n",
    "df_budget.index = pd.to_datetime(df_budget.index) + pd.DateOffset(month=12)\n",
    "\n",
    "# # Convert the index to the desired format\n",
    "df_budget.index = df_budget.index.strftime('%Y-%m')\n",
    "\n",
    "# Adjust the index name\n",
    "df_budget.rename_axis('Time', inplace=True)\n",
    "\n",
    "# Export the dataframe to an excel file\n",
    "df_budget.to_csv('../data/df_budget.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
