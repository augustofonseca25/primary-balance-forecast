{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f3c1263",
   "metadata": {},
   "source": [
    "### This is the code to grid search some parameters to create a GRU model\n",
    "#### References:\n",
    "- Peixeiro, M. (2022). Time series forecasting in Python. Manning. Includes the codes fromi its GitHub repo (https://github.com/marcopeix/AppliedTimeSeriesForecastingInPython).   \n",
    "Contribution: The technique for converting the series into sequenced samples and the idea for scale and reeschale data after predictions.\n",
    "- Discolll, N. (2024, January 12). Harnessing RNNs for Financial Time Series Analysis: A Python Approach. Medium. https://medium.com/@redeaddiscolll/harnessing-rnns-for-financial-time-series-analysis-a-python-approach-0669b3a25c7a.   \n",
    "Contribution: EarlyStopping function.\n",
    "\n",
    "#### Libraries\n",
    "- Package Pandas (2.2). (2024). [Python]. https://pandas.pydata.org/\n",
    "- Package NumPy (1.23). (2023). [Pyhton]. https://numpy.org/ - Harris, C. R., Millman, K. J., Van Der Walt, S. J., Gommers, R., Virtanen, P., Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N. J., Kern, R., Picus, M., Hoyer, S., Van Kerkwijk, M. H., Brett, M., Haldane, A., Del Río, J. F., Wiebe, M., Peterson, P., … Oliphant, T. E. (2020). Array programming with NumPy. Nature, 585(7825), 357–362. https://doi.org/10.1038/s41586-020-2649-2\n",
    "- Droettboom, J. D. H., Michael. (2024). Package matplotlib (3.8.4) [Python]. https://matplotlib.org\n",
    "- Package scikit-learn (1.4). (2024). [Pyhton]. https://scikit-learn.org/stable/index.html\n",
    "- Package Tensorflow (2.16). (2024). [Python]. https://github.com/tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27e86681",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27e86681",
    "outputId": "1af8a1db-879d-44d0-b1df-07a82eaa1fb8"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import random as python_random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (mean_absolute_error,\n",
    "                             mean_absolute_percentage_error,\n",
    "                             mean_squared_error)\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "import useful_functions as uf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cs469n2XOr_-",
   "metadata": {
    "id": "cs469n2XOr_-"
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "#file_path = '../data/data_orig_parameters.csv'\n",
    "#file_path = '../data/data_cleaned_RF.csv'\n",
    "file_path = '../data/data_cleaned_LASSO.csv'\n",
    "#file_path = '../data/data_cleaned_RFE.csv'\n",
    "\n",
    "# parse the date column and set it as the index of the dataframe\n",
    "df_raw = pd.read_csv(file_path, parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "# define the target variable as the first column\n",
    "target_variable = df_raw.columns[0]\n",
    "\n",
    "# Convert all columns to float\n",
    "df_raw = df_raw.astype('float64')\n",
    "\n",
    "# Define a threshold to remove outliers\n",
    "remove_outliers_threshold = np.nan # No outliers removed\n",
    "#remove_outliers_threshold = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e06252c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers based on the threshold\n",
    "if not pd.isna(remove_outliers_threshold): # If the threshold is not NaN, remove outliers\n",
    "    df_cleaned = uf.remove_outliers(df_raw.copy(), threshold=remove_outliers_threshold)\n",
    "else: # Otherwise, keep the original dataframe\n",
    "    df_cleaned = df_raw.copy()\n",
    "\n",
    "# Given outliers were removed, fill missing values\n",
    "df_adjusted = uf.fill_missing_values(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5ef4449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test and validation set sizes\n",
    "val_size = 48 # 48 months or 4 years\n",
    "test_size = 48 # 48 months or 4 years\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_raw_total = df_adjusted.copy()[:-test_size] # This total trainning set will be used to train the final model\n",
    "train_raw = train_raw_total[:-val_size]\n",
    "val_raw = train_raw_total[-val_size:]\n",
    "test_raw = df_adjusted.copy()[-test_size:]\n",
    "\n",
    "# Fill missing values\n",
    "df_train = uf.fill_missing_values(train_raw)\n",
    "df_val = uf.fill_missing_values(val_raw)\n",
    "df_test = uf.fill_missing_values(test_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db93b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let´s scale the dfs\n",
    "# Create a scaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train = scaler.fit_transform(df_train) # Fit and transform the train set\n",
    "scaled_val = scaler.transform(df_val) # Transform the validation set\n",
    "scaled_test = scaler.transform(df_test) # Transform the test set\n",
    "\n",
    "# include df columns names in the train and test sets\n",
    "train = pd.DataFrame(scaled_train, columns=df_train.columns)\n",
    "val = pd.DataFrame(scaled_val, columns=df_val.columns)\n",
    "test = pd.DataFrame(scaled_test, columns=df_test.columns)\n",
    "\n",
    "# Include the index in the train and test sets\n",
    "train.index = df_train.index\n",
    "val.index = df_val.index\n",
    "test.index = df_test.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f39293",
   "metadata": {},
   "source": [
    "Reshape your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e25733e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the series to samples\n",
    "# We will use the past 12 months to predict a month 12 months in the future\n",
    "def createXY(dataset, n_past, n_future):\n",
    "    dataX, dataY = [], []\n",
    "    # Loop for the entire dataset\n",
    "    for i in range(n_past, len(dataset) - n_future + 1):\n",
    "        dataX.append(dataset.iloc[i - n_past:i].values)  # Past n months\n",
    "        dataY.append(dataset.iloc[i + n_future - 1, 0])  #\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "n_past = 12  # Number of past months to use\n",
    "n_future = 1  # Forecast horizon\n",
    "\n",
    "# Create the samples\n",
    "X_train, Y_train = createXY(train, n_past, n_future)\n",
    "X_val, Y_val = createXY(val, n_past, n_future)\n",
    "X_test, Y_test = createXY(test, n_past, n_future)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e3f8c6",
   "metadata": {},
   "source": [
    "### Let's grid to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85beeaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define the seed for reproducibility\n",
    "\n",
    "def func_set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    python_random.seed(seed)\n",
    "    set_seed(seed) #tensorflow.random.set_seed(seed)\n",
    "\n",
    "# Call the function to set the seed\n",
    "func_set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15a5db0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  1 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  2 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  3 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  4 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  5 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  6 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  7 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  8 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  9 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  10 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  11 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  12 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  13 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  14 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  15 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  16 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  17 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  18 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  19 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  20 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  21 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  22 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  23 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  24 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  25 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  26 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  27 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  28 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  29 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  30 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  31 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  32 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  33 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  34 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  35 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  36 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  37 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  38 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  39 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  40 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  41 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  42 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  43 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  44 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  45 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  46 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  47 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  48 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  49 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  50 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  51 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  52 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  53 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  54 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  55 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  56 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  57 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  58 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  59 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  60 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  61 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  62 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  63 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  64 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  65 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  66 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  67 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  68 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  69 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  70 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  71 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  72 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  73 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  74 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  75 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  76 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  77 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  78 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  79 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  80 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  81 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  82 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  83 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  84 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  85 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  86 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  87 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  88 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  89 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  90 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  91 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  92 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  93 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  94 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  95 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  96 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  97 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  98 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  99 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  100 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  101 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  102 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  103 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  104 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  105 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  106 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  107 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  108 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  109 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  110 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  111 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  112 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  113 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  114 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  115 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  116 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  117 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  118 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  119 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  120 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  121 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  122 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  123 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  124 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  125 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  126 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  127 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  128 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  129 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  130 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  131 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  132 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  133 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  134 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  135 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  136 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  137 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  138 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  139 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  140 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  141 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  142 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  143 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  144 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  145 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  146 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  147 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  148 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  149 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  150 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  151 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  152 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  153 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  154 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  155 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  156 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  157 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  158 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  159 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  160 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  161 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  162 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  163 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  164 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  165 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  166 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  167 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  168 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  169 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  170 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  171 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  172 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  173 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  174 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  175 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  176 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  177 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  178 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  179 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  180 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  181 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  182 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  183 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  184 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  185 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  186 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  187 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  188 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  189 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  190 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  191 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  192 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  193 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  194 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  195 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  196 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  197 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  198 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  199 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  200 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  201 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  202 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  203 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  204 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  205 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  206 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  207 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  208 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  209 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  210 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  211 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  212 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  213 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  214 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  215 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  216 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  217 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  218 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  219 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  220 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  221 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  222 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  223 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  224 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  225 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  226 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  227 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  228 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  229 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  230 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  231 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  232 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  233 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  234 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  235 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  236 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  237 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  238 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  239 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  240 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  241 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  242 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  243 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  244 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  245 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  246 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  247 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  248 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  249 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  250 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  251 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  252 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  253 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  254 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  255 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  256 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  257 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  258 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  259 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  260 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  261 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  262 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  263 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  264 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  265 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  266 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  267 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  268 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  269 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  270 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  271 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  272 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  273 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  274 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  275 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  276 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  277 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  278 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  279 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  280 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  281 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  282 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  283 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  284 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  285 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  286 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  287 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  288 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  289 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  290 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  291 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  292 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  293 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  294 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  295 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  296 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  297 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  298 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  299 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  300 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  301 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  302 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  303 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  304 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  305 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  306 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  307 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  308 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  309 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  310 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  311 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  312 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  313 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  314 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  315 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  316 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  317 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  318 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  319 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  320 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  321 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  322 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  323 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  324 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  325 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  326 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  327 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  328 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  329 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  330 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  331 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  332 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  333 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  334 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  335 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  336 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  337 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  338 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  339 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  340 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  341 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  342 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  343 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  344 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  345 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  346 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  347 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  348 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  349 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  350 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  351 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  352 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  353 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  354 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  355 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  356 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  357 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  358 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  359 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  360 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  361 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  362 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  363 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  364 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  365 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  366 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  367 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  368 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  369 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  370 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  371 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  372 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  373 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  374 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  375 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  376 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  377 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  378 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  379 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  380 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  381 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  382 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  383 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  384 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  385 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  386 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  387 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  388 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  389 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  390 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  391 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  392 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  393 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  394 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  395 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  396 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  397 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  398 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  399 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  400 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  401 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  402 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  403 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  404 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  405 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  406 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  407 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  408 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  409 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  410 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  411 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  412 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  413 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  414 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  415 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  416 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  417 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  418 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  419 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  420 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  421 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  422 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  423 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  424 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  425 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  426 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  427 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  428 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  429 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  430 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  431 th iteration\n",
      "Applying parameters:  {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  432 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  433 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  434 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  435 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  436 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  437 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  438 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  439 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  440 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  441 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  442 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  443 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  444 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  445 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  446 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  447 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  448 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  449 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  450 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  451 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  452 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  453 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  454 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  455 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  456 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  457 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  458 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  459 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  460 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  461 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  462 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  463 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  464 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  465 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  466 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  467 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  468 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  469 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  470 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  471 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  472 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  473 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  474 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  475 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  476 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  477 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  478 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  479 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  480 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  481 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  482 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  483 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  484 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  485 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  486 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  487 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  488 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  489 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  490 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  491 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  492 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  493 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  494 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  495 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  496 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  497 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  498 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  499 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  500 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  501 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  502 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  503 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  504 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  505 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  506 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  507 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  508 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  509 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  510 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  511 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  512 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  513 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  514 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  515 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  516 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  517 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  518 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  519 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  520 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  521 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  522 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  523 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  524 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  525 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  526 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  527 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  528 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  529 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  530 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  531 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  532 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  533 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  534 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  535 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  536 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  537 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  538 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  539 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  540 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  541 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  542 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  543 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  544 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  545 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  546 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  547 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  548 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  549 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  550 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  551 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  552 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  553 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  554 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  555 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  556 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  557 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  558 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  559 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  560 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  561 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  562 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  563 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  564 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  565 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  566 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  567 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  568 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  569 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  570 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  571 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  572 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  573 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  574 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  575 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.1, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  576 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  577 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  578 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  579 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  580 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  581 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  582 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  583 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  584 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  585 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  586 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  587 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  588 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  589 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  590 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  591 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  592 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  593 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  594 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  595 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  596 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  597 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  598 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  599 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  600 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  601 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  602 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  603 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  604 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  605 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  606 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  607 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  608 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  609 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  610 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  611 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  612 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  613 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  614 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  615 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  616 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  617 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  618 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  619 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  620 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  621 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  622 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  623 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  624 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  625 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  626 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  627 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  628 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  629 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  630 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  631 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  632 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  633 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  634 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  635 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  636 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  637 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  638 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  639 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  640 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  641 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  642 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  643 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  644 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  645 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  646 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  647 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  648 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  649 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  650 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  651 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  652 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  653 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  654 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  655 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  656 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  657 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  658 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  659 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  660 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  661 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  662 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  663 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  664 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  665 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  666 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  667 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  668 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  669 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  670 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  671 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  672 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  673 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  674 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  675 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  676 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  677 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  678 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  679 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  680 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  681 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  682 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  683 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  684 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  685 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  686 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  687 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  688 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  689 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  690 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  691 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  692 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  693 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  694 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  695 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  696 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  697 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  698 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  699 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  700 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  701 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  702 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  703 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  704 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  705 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  706 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  707 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  708 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  709 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  710 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  711 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  712 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  713 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  714 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  715 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  716 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  717 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  718 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  719 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  720 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  721 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  722 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  723 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  724 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  725 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  726 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  727 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  728 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  729 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  730 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  731 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  732 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  733 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  734 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  735 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  736 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  737 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  738 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  739 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  740 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  741 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  742 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  743 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  744 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  745 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  746 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  747 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  748 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  749 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  750 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  751 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  752 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  753 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  754 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  755 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  756 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  757 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  758 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  759 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  760 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  761 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  762 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  763 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  764 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  765 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  766 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  767 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 30, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  768 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  769 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  770 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  771 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  772 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  773 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  774 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  775 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  776 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  777 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  778 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  779 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  780 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  781 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  782 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  783 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  784 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  785 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  786 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  787 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  788 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  789 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  790 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  791 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  792 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  793 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  794 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  795 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  796 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  797 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  798 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  799 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  800 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  801 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  802 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  803 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  804 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  805 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  806 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  807 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  808 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  809 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  810 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  811 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  812 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  813 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  814 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  815 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  816 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  817 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  818 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  819 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  820 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  821 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  822 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  823 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  824 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  825 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  826 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  827 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  828 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  829 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  830 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  831 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  832 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  833 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  834 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  835 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  836 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  837 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  838 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  839 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 50, 2: 20, 3: 15}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  840 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  841 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  842 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  843 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  844 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  845 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  846 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  847 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  848 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  849 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  850 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  851 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 100, 2: 100, 3: 50}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  852 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  853 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  854 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  855 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  856 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  857 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  858 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'adam'} . This is the  859 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 1, 'optimizer': 'rmsprop'} . This is the  860 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'adam'} . This is the  861 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 2, 'optimizer': 'rmsprop'} . This is the  862 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'adam'} . This is the  863 th iteration\n",
      "Applying parameters:  {'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 75, 'gru_units': {1: 200, 2: 200, 3: 100}, 'learning_rate': 0.0001, 'n_layers': 3, 'optimizer': 'rmsprop'} . This is the  864 th iteration\n",
      "Best Score: 0.024256983771920204\n",
      "Best Parameters: {'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 50, 'gru_units': {1: 10, 2: 10, 3: 5}, 'learning_rate': 0.001, 'n_layers': 1, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "### Build a GRU model testing different parameters\n",
    "\n",
    "# Function to build the model\n",
    "def build_model(n_layers = 2,  # Number of hidden layers\n",
    "                optimizer='adam',  # Optimizer\n",
    "                learning_rate=0.001,  # Learning rate for the optimizer\n",
    "                gru_units={0: 50,  1: 20, 2: 10}, # Number of units in the GRU layers\n",
    "                #alphas_l1_l2=0.01, # Removed regularization for now, because it was not improving the model\n",
    "                dropout_rate=0.1 # Dropout rate to avoid overfitting\n",
    "                ):\n",
    "    \n",
    "    # Check the optimizer\n",
    "    if optimizer == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    \n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "    # Define the input layer shape\n",
    "    model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    # Add the GRU layers\n",
    "    for i in range(n_layers):\n",
    "        if i < n_layers - 1:  # intermediate hidden layers\n",
    "            model.add(GRU(units=gru_units[i+1],\n",
    "                                # Removed regularization for now, because it was not improving the model\n",
    "                                #kernel_regularizer=l1_l2(l1=alphas_l1_l2, l2=alphas_l1_l2), \n",
    "                                #recurrent_regularizer=l1_l2(l1=alphas_l1_l2, l2=alphas_l1_l2),\n",
    "                                #bias_regularizer=l1_l2(l1=alphas_l1_l2, l2=alphas_l1_l2),\n",
    "                                return_sequences=True))\n",
    "            model.add(Dropout(dropout_rate))\n",
    "        else:  # last hidden layer\n",
    "            model.add(GRU(units=gru_units[i+1],\n",
    "                                # Removed regularization for now, because it was not improving the model\n",
    "                                #kernel_regularizer=l1_l2(l1=alphas_l1_l2, l2=alphas_l1_l2), \n",
    "                                #recurrent_regularizer=l1_l2(l1=alphas_l1_l2, l2=alphas_l1_l2),\n",
    "                                #bias_regularizer=l1_l2(l1=alphas_l1_l2, l2=alphas_l1_l2)))\n",
    "                                return_sequences=False))\n",
    "            model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=1)) #output layer\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Function to test each set of parameters\n",
    "def custom_fit(params):\n",
    "    # Get the parameters to train the model\n",
    "    training_params = {key: params[key] for key in params if key in ['n_layers', \n",
    "                                                                     #'alphas_l1_l2',# Removed regularization for now, because it was not improving the model\n",
    "                                                                     'dropout_rate',\n",
    "                                                                     'gru_units', \n",
    "                                                                     'optimizer', \n",
    "                                                                     'learning_rate']}\n",
    "    model = build_model(**training_params) # Create the model\n",
    "    \n",
    "    # Define EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True) # Stop training when the validation loss is no longer decreasing after X epochs\n",
    "\n",
    "    # Fitting the model with early stopping\n",
    "    model.fit(X_train, Y_train, \n",
    "              epochs=params['epochs'], \n",
    "              batch_size=params['batch_size'], \n",
    "              verbose=0,\n",
    "              validation_data=(X_val, Y_val), \n",
    "              callbacks=[early_stopping])\n",
    "    \n",
    "    # Compute the loss on the validation set to compare the models\n",
    "    loss = model.evaluate(X_val, Y_val, verbose=0)\n",
    "    return loss\n",
    "\n",
    "# Parameters to test\n",
    "param_grid = {\n",
    "    'dropout_rate': [0.1, 0.2, 0.3],\n",
    "    #'alphas_l1_l2' : [0.001, 0.01, 0.1, 1],\n",
    "    'batch_size': [32, 64],\n",
    "    'epochs': [30, 50, 75],\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'learning_rate': [0.001, 0.0001], # Learning rate\n",
    "    'n_layers': [1,2,3], # Number of hidden layers\n",
    "    'gru_units' : [{1: 10,  2: 10, 3: 5}, {1: 50,  2: 20, 3: 15},\n",
    "                   {1: 100,  2: 100, 3: 50}, {1: 200,  2: 200, 3: 100}]  \n",
    "}\n",
    "\n",
    "# Compare the scores for each set of parameters\n",
    "best_score = np.inf\n",
    "best_params = None\n",
    "interactions = 1\n",
    "# Loop through all the parameters in the grid\n",
    "for params in ParameterGrid(param_grid): # For each set of parameters\n",
    "    print(\"Applying parameters: \", params,\". This is the \", interactions, \"th iteration\")\n",
    "    interactions += 1\n",
    "    score = custom_fit(params) # Train the model and get the score\n",
    "    if score < best_score: # If the score is better than the best score\n",
    "        best_score = score # Update the best score\n",
    "        best_params = params # Update the best parameters\n",
    "\n",
    "# Print the best score and best parameters\n",
    "print(f'Best Score: {best_score}')\n",
    "print(f'Best Parameters: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d59d3db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's build the model with the best parameters and train it\n",
    "# Get epochs and batch_size from best_params\n",
    "best_params_bkp = best_params.copy()\n",
    "epochs = best_params.pop('epochs')\n",
    "batch_size = best_params.pop('batch_size')\n",
    "\n",
    "# build the model\n",
    "best_model_GRU = build_model(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a90bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model - Adjust the file name based on the used dataset and patience\n",
    "best_model_GRU.save('models_parameters/RNN_LASSO_BS_128_EP_20_PT_10.keras')  # Saves the model to a keras file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "566c1b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we need to restore the best model\n",
    "\n",
    "# # Load the model from the file\n",
    "# best_model = load_model('best_gru_model_grid.keras')\n",
    "# # from manual hyperparameter tuning\n",
    "# epochs = 20\n",
    "# batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "544e7993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 - 4s - 682ms/step - loss: 1.5538 - val_loss: 0.1489\n",
      "Epoch 2/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.7571 - val_loss: 0.0384\n",
      "Epoch 3/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.3440 - val_loss: 0.1152\n",
      "Epoch 4/50\n",
      "6/6 - 0s - 15ms/step - loss: 0.1934 - val_loss: 0.2422\n",
      "Epoch 5/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.1512 - val_loss: 0.3150\n",
      "Epoch 6/50\n",
      "6/6 - 0s - 16ms/step - loss: 0.1971 - val_loss: 0.3263\n",
      "Epoch 7/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.1809 - val_loss: 0.2799\n",
      "Epoch 8/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.1345 - val_loss: 0.2318\n",
      "Epoch 9/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.1195 - val_loss: 0.1916\n",
      "Epoch 10/50\n",
      "6/6 - 0s - 28ms/step - loss: 0.1054 - val_loss: 0.1628\n",
      "Epoch 11/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.0949 - val_loss: 0.1480\n",
      "Epoch 12/50\n",
      "6/6 - 0s - 15ms/step - loss: 0.0875 - val_loss: 0.1429\n",
      "Epoch 13/50\n",
      "6/6 - 0s - 17ms/step - loss: 0.0961 - val_loss: 0.1466\n",
      "Epoch 14/50\n",
      "6/6 - 0s - 15ms/step - loss: 0.0952 - val_loss: 0.1530\n",
      "Epoch 15/50\n",
      "6/6 - 0s - 15ms/step - loss: 0.0954 - val_loss: 0.1594\n",
      "Epoch 16/50\n",
      "6/6 - 0s - 26ms/step - loss: 0.0824 - val_loss: 0.1551\n",
      "Epoch 17/50\n",
      "6/6 - 0s - 28ms/step - loss: 0.0722 - val_loss: 0.1470\n",
      "Epoch 18/50\n",
      "6/6 - 0s - 15ms/step - loss: 0.0850 - val_loss: 0.1422\n",
      "Epoch 19/50\n",
      "6/6 - 0s - 27ms/step - loss: 0.0782 - val_loss: 0.1356\n",
      "Epoch 20/50\n",
      "6/6 - 0s - 16ms/step - loss: 0.0960 - val_loss: 0.1270\n",
      "Epoch 21/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.0727 - val_loss: 0.1242\n",
      "Epoch 22/50\n",
      "6/6 - 0s - 29ms/step - loss: 0.0719 - val_loss: 0.1241\n",
      "Epoch 23/50\n",
      "6/6 - 0s - 15ms/step - loss: 0.0485 - val_loss: 0.1229\n",
      "Epoch 24/50\n",
      "6/6 - 0s - 29ms/step - loss: 0.0586 - val_loss: 0.1227\n",
      "Epoch 25/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.0672 - val_loss: 0.1185\n",
      "Epoch 26/50\n",
      "6/6 - 0s - 15ms/step - loss: 0.0615 - val_loss: 0.1012\n",
      "Epoch 27/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.0688 - val_loss: 0.0919\n",
      "Epoch 28/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.0594 - val_loss: 0.0885\n",
      "Epoch 29/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.0555 - val_loss: 0.0892\n",
      "Epoch 30/50\n",
      "6/6 - 0s - 46ms/step - loss: 0.0741 - val_loss: 0.0878\n",
      "Epoch 31/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.0479 - val_loss: 0.0840\n",
      "Epoch 32/50\n",
      "6/6 - 0s - 28ms/step - loss: 0.0571 - val_loss: 0.0801\n",
      "Epoch 33/50\n",
      "6/6 - 0s - 19ms/step - loss: 0.0493 - val_loss: 0.0719\n",
      "Epoch 34/50\n",
      "6/6 - 0s - 18ms/step - loss: 0.0580 - val_loss: 0.0694\n",
      "Epoch 35/50\n",
      "6/6 - 0s - 16ms/step - loss: 0.0494 - val_loss: 0.0666\n",
      "Epoch 36/50\n",
      "6/6 - 0s - 16ms/step - loss: 0.0417 - val_loss: 0.0612\n",
      "Epoch 37/50\n",
      "6/6 - 0s - 15ms/step - loss: 0.0466 - val_loss: 0.0564\n",
      "Epoch 38/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.0381 - val_loss: 0.0539\n",
      "Epoch 39/50\n",
      "6/6 - 0s - 15ms/step - loss: 0.0400 - val_loss: 0.0523\n",
      "Epoch 40/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.0430 - val_loss: 0.0502\n",
      "Epoch 41/50\n",
      "6/6 - 0s - 16ms/step - loss: 0.0515 - val_loss: 0.0460\n",
      "Epoch 42/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.0372 - val_loss: 0.0452\n",
      "Epoch 43/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.0451 - val_loss: 0.0462\n",
      "Epoch 44/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.0489 - val_loss: 0.0470\n",
      "Epoch 45/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.0451 - val_loss: 0.0471\n",
      "Epoch 46/50\n",
      "6/6 - 0s - 15ms/step - loss: 0.0517 - val_loss: 0.0464\n",
      "Epoch 47/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.0412 - val_loss: 0.0461\n",
      "Epoch 48/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.0547 - val_loss: 0.0436\n",
      "Epoch 49/50\n",
      "6/6 - 0s - 14ms/step - loss: 0.0491 - val_loss: 0.0417\n",
      "Epoch 50/50\n",
      "6/6 - 0s - 29ms/step - loss: 0.0445 - val_loss: 0.0417\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = best_model_GRU.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "# Make predictions\n",
    "predictions_scaled = best_model_GRU.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62bd6363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('GRU training - Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "016ae6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE GRU: 1.4292993545532227\n",
      "RMSE GRU: 21593.787109375\n",
      "MAE GRU: 16288.359375\n"
     ]
    }
   ],
   "source": [
    "# Let's reshape the predictions and Y_val to revert the scaling\n",
    "# Reshape predictions to 2D\n",
    "predictions_scaled_2d = predictions_scaled.reshape(-1, 1)\n",
    "\n",
    "# Get the last timestep of X_val\n",
    "X_val_last_timestep = X_val[:, -1, :]\n",
    "\n",
    "# Replace the first column of X_val_last_timestep with the scaled predictions.\n",
    "X_val_last_timestep[:, 0] = predictions_scaled_2d[:, 0]\n",
    "\n",
    "# unscale the predictions\n",
    "predictions_rescaled = scaler.inverse_transform(X_val_last_timestep)[:, 0]\n",
    "\n",
    "# unscale the Y_val\n",
    "Y_val_rescaled = scaler.inverse_transform(val.iloc[-len(predictions_scaled):, :].values)[:, 0]\n",
    "\n",
    "# Calculate the error\n",
    "mape_GRU_val = mean_absolute_percentage_error(Y_val_rescaled, predictions_rescaled)\n",
    "rmse_GRU_val = np.sqrt(mean_squared_error(Y_val_rescaled, predictions_rescaled))\n",
    "mae_GRU_val = mean_absolute_error(Y_val_rescaled, predictions_rescaled)\n",
    "\n",
    "print(f'MAPE GRU: {mape_GRU_val}')\n",
    "print(f'RMSE GRU: {rmse_GRU_val}')\n",
    "print(f'MAE GRU: {mae_GRU_val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e719f5",
   "metadata": {},
   "source": [
    "### Predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a80f71c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n"
     ]
    }
   ],
   "source": [
    "# Let's predict the test set using the best model\n",
    "predictions_test_scaled = best_model_GRU.predict(X_test)\n",
    "\n",
    "# Let's reshape the predictions and Y_val to revert the scaling\n",
    "# Reshape predictions to 2D\n",
    "predictions_test_scaled_2d = predictions_test_scaled.reshape(-1, 1)\n",
    "\n",
    "# Get the last timestep of X_test\n",
    "X_test_last_timestep = X_test[:, -1, :]\n",
    "\n",
    "# Replace the first column of X_test_last_timestep with the scaled predictions.\n",
    "X_test_last_timestep[:, 0] = predictions_test_scaled_2d[:, 0]\n",
    "\n",
    "# unscale the predictions\n",
    "predictions_test_rescaled = scaler.inverse_transform(X_test_last_timestep)[:, 0]\n",
    "\n",
    "# Let's convert the predictions and Y_test to a dataframe usind the index from test\n",
    "predictions_test_df = pd.DataFrame(predictions_test_rescaled, index=test.index[-len(predictions_test_rescaled):], columns=[target_variable])\n",
    "predictions = predictions_test_df.copy()\n",
    "\n",
    "# Get the original Y_test values to compare\n",
    "Y_test = df_adjusted[-len(predictions):][target_variable]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5a61945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE best GRU: 3.192638874053955\n",
      "RMSE best GRU: 47781.15625\n",
      "MAE best GRU: 38938.859375\n"
     ]
    }
   ],
   "source": [
    "# Calculate the error\n",
    "mape_best_GRU = mean_absolute_percentage_error(Y_test, predictions)\n",
    "rmse_best_GRU = np.sqrt(mean_squared_error(Y_test, predictions))\n",
    "mae_best_GRU = mean_absolute_error(Y_test, predictions)\n",
    "\n",
    "print(f'MAPE best GRU: {mape_best_GRU}')\n",
    "print(f'RMSE best GRU: {rmse_best_GRU}')\n",
    "print(f'MAE best GRU: {mae_best_GRU}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bff39e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot GRU best Model Predictions vs Actuals - test Set\n",
    "\n",
    "# Convert Y_test_rescaled to a dataframe using the test index\n",
    "Y_test_rescaled_df = pd.DataFrame(Y_test, index=Y_test.index)\n",
    "\n",
    "# Change the column name to the target variable\n",
    "Y_test_rescaled_df.columns = [target_variable]\n",
    "\n",
    "uf.plot_prediction_vs_test(\n",
    "    target_variable, \n",
    "    Y_test_rescaled_df[target_variable],\n",
    "    predictions,\n",
    "    'GRU Model Predictions vs Actuals - Test Set',)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
