{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the code to iterate throught subset datasets and outliers thresholds using SARIMAX model to get error metrics. \n",
    "#### References: \n",
    "- Kalyvas, V. (2024, January 19). Time Series Episode 3: ARIMA predictioning with exogenous variables. Medium. https://python.plainenglish.io/time-series-episode-3-arima-forecasting-with-exogenous-variables-6658f82170e4  \n",
    "Contribution: The logic for SARIMA implementation with exogenous variables.\n",
    "- Peixeiro, M. (2022). Time series forecasting in Python (Section 9). Manning.  \n",
    "Contribution: The logic for residual analysis and the implementation of the Ljung-Box test.\n",
    "\n",
    "\n",
    "#### Libraries\n",
    "- Package Pandas (2.2). (2024). [Python]. https://pandas.pydata.org/\n",
    "- Package NumPy (1.23). (2023). [Pyhton]. https://numpy.org/ - Harris, C. R., Millman, K. J., Van Der Walt, S. J., Gommers, R., Virtanen, P., Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N. J., Kern, R., Picus, M., Hoyer, S., Van Kerkwijk, M. H., Brett, M., Haldane, A., Del Río, J. F., Wiebe, M., Peterson, P., … Oliphant, T. E. (2020). Array programming with NumPy. Nature, 585(7825), 357–362. https://doi.org/10.1038/s41586-020-2649-2\n",
    "- Droettboom, J. D. H., Michael. (2024). Package matplotlib (3.8.4) [Python]. https://matplotlib.org\n",
    "- Package scikit-learn (1.4). (2024). [Pyhton]. https://scikit-learn.org/stable/index.html\n",
    "- Package statsmodels (0.14). (2024). [Python]. statsmodels. https://github.com/statsmodels/statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REading File: ../data/data_cleaned_LASSO.csv\n",
      "Outlier Threshold: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\My Drive\\Data_Projects\\MDS\\master_thesis\\fiscal-balance-forecast\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "g:\\My Drive\\Data_Projects\\MDS\\master_thesis\\fiscal-balance-forecast\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "g:\\My Drive\\Data_Projects\\MDS\\master_thesis\\fiscal-balance-forecast\\.venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import (mean_absolute_error,\n",
    "                             mean_absolute_percentage_error,\n",
    "                             mean_squared_error)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "import useful_functions as uf\n",
    "\n",
    "# Define a list of file paths\n",
    "file_paths = [\n",
    "    '../data/data_orig_parameters.csv',\n",
    "    '../data/data_cleaned_RF.csv',\n",
    "    '../data/data_cleaned_LASSO.csv',\n",
    "    '../data/data_cleaned_RFE.csv'\n",
    "]\n",
    "\n",
    "# List of thresholds for outliers\n",
    "outlier_thresholds = [np.nan, 0.05, 0.10, 0.15, 0.20]\n",
    "\n",
    "# Dictionary to store the errors\n",
    "errors_dict = {}\n",
    "\n",
    "# Loop through the files and thresholds\n",
    "for file_path in file_paths:\n",
    "    print(f\"REading File: {file_path}\") # Print the file path\n",
    "    for remove_outliers_threshold in outlier_thresholds:\n",
    "        print(f\"Outlier Threshold: {remove_outliers_threshold}\") # Print the threshold\n",
    "        # Load data\n",
    "        df_raw = pd.read_csv(file_path, parse_dates=['Date'], index_col='Date')\n",
    "        target_variable = df_raw.columns[0]\n",
    "\n",
    "        # Remove outliers using the threshold\n",
    "        if not pd.isna(remove_outliers_threshold):\n",
    "            df_cleaned = uf.remove_outliers(df_raw.copy(), threshold=remove_outliers_threshold)\n",
    "        else:\n",
    "            df_cleaned = df_raw.copy()\n",
    "\n",
    "        # After removing the outliers, fill the missing values\n",
    "        df_adjusted = uf.fill_missing_values(df_cleaned)\n",
    "\n",
    "        # Define the train and test sets\n",
    "        test_size = 48  # meses\n",
    "        df_train = df_adjusted[:-test_size]\n",
    "        df_test = df_adjusted[-test_size:]\n",
    "\n",
    "        # Let´s scale the dfs\n",
    "        # Define the scaler\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        scaled_train = scaler.fit_transform(df_train) # Fit and transform the train set\n",
    "        scaled_test = scaler.transform(df_test) # Transform the test set\n",
    "        # include df columns names in the train and test sets\n",
    "        train = pd.DataFrame(scaled_train, columns=df_adjusted.columns)\n",
    "        test = pd.DataFrame(scaled_test, columns=df_adjusted.columns)\n",
    "        # Include the index in the train and test sets\n",
    "        train.index = df_adjusted.index[:-test_size]\n",
    "        test.index = df_adjusted.index[-test_size:]\n",
    "        # define the exogenous variables as all except the first column\n",
    "        exog_var_train = train.iloc[:, 1:].ffill() # fill NAs with the last valid observation\n",
    "        exog_var_test = test.iloc[:, 1:].ffill()# fill NAs with the last valid observation\n",
    "        # Define the model using the same parameters as the SARIMA\n",
    "        model = SARIMAX(train[target_variable], order=(5,1,4), \n",
    "                        seasonal_order=(2,0,0,12), exog = exog_var_train)\n",
    "        # Fit the model\n",
    "        model_fit = model.fit(disp=False, maxiter=200)\n",
    "        # Predict the test set\n",
    "        predictions = model_fit.forecast(steps=len(test[target_variable]), exog = exog_var_test)\n",
    "\n",
    "        # Let's reverse the scaling to get the real values\n",
    "        original_data_test = df_adjusted[-test_size:][target_variable]\n",
    "        # Convert Pandas Series to NumPy arrays and reshape\n",
    "        predictions_on_test_scaled_np = predictions.to_numpy().reshape(-1, 1)\n",
    "        predictions_on_test_scaled_np = np.repeat(predictions_on_test_scaled_np,test.shape[1], axis=-1)\n",
    "\n",
    "        # Inverse transform to get the real values\n",
    "        predictions_on_test_all = scaler.inverse_transform(predictions_on_test_scaled_np)\n",
    "\n",
    "        # Subset the forecast to get only the first column\n",
    "        predictions_on_test = predictions_on_test_all[:,0]\n",
    "\n",
    "        # Convert to pandas dataframe and include the index\n",
    "        predictions_on_test = pd.DataFrame(predictions_on_test, index=test.index, columns=[target_variable])\n",
    "\n",
    "        # Calculate the errors\n",
    "        mape = mean_absolute_percentage_error(original_data_test, predictions_on_test)\n",
    "        rmse = np.sqrt(mean_squared_error(original_data_test, predictions_on_test))\n",
    "        mae = mean_absolute_error(original_data_test, predictions_on_test)\n",
    "\n",
    "        # Save the erros and the model summary in the dictionary\n",
    "        errors_dict[(file_path, remove_outliers_threshold)] = {'MAPE': mape, 'RMSE': rmse, 'MAE': mae, 'model': model_fit.summary(),'predictions': predictions_on_test}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SARIMAX., File: ../data/data_cleaned_LASSO.csv, Outlier Threshold: 0.2 ->, MAPE: 1.83, RMSE: 22488.57, MAE: 15968.34\n"
     ]
    }
   ],
   "source": [
    "# Print the errors to evaluate the best model\n",
    "for key, value in errors_dict.items():\n",
    "    mape = value['MAPE']\n",
    "    rmse = value['RMSE']\n",
    "    mae = value['MAE']\n",
    "    print(f\"Model: SARIMAX., File: {key[0]}, Outlier Threshold: {key[1]} ->, MAPE: {mape:.2f}, RMSE: {rmse:.2f}, MAE: {mae:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
